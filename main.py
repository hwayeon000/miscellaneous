from fastapi import FastAPI, Request, Form, UploadFile, File
from fastapi.templating import Jinja2Templates
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse
import google.generativeai as genai
import os
from typing import Optional
from dotenv import load_dotenv
import time
from collections import defaultdict

# ê°„ë‹¨í•œ ì‚¬ìš©ëŸ‰ ì¶”ì  (ì‹¤ì œ ì„œë²„ì—ì„œëŠ” ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© ê¶Œì¥)
usage_tracker = {
    'requests_today': 0,
    'last_reset': time.strftime('%Y-%m-%d'),
    'requests_this_minute': defaultdict(int)
}

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI()

# Jinja2 í…œí”Œë¦¿ ì„¤ì •
templates = Jinja2Templates(directory="templates")

# Gemini API ì„¤ì •
load_dotenv()
GEMINI_API_KEY = os.getenv('API_KEY')

# API í‚¤ ê²€ì¦
if not GEMINI_API_KEY or GEMINI_API_KEY == "YOUR_GEMINI_API_KEY_HERE":
    print("âš ï¸ ê²½ê³ : API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”!")
    print("í™˜ê²½ë³€ìˆ˜ API_KEYë¥¼ ì„¤ì •í•˜ê±°ë‚˜ .env íŒŒì¼ì— API_KEY=your_key_here ë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
    print("Google AI Studioì—ì„œ API í‚¤ë¥¼ ë°œê¸‰ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤: https://makersuite.google.com/app/apikey")
else:
    print(f"âœ… API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤: {GEMINI_API_KEY[:10]}...")

genai.configure(api_key=GEMINI_API_KEY)


# ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ í™•ì¸ ë° ì„¤ì • (ë¬´ë£Œ ì‚¬ìš©ëŸ‰ ìµœì í™”)
try:
    optimal_models = [
        ('gemini-1.5-flash', 'ì¼ë°˜ ì‚¬ìš© - 10 RPM, 250 RPD'),
        ('gemini-1.5-flash-lite', 'ì ˆì•½ ëª¨ë“œ - 15 RPM, 1000 RPD'),  
        ('gemini-2.5-flash', 'ìµœì‹  ë²„ì „ - 10 RPM'),
        ('gemini-1.0-pro', 'ê¸°ë³¸ ëª¨ë¸ - ì•ˆì •ì ')
    ]
    
    model = None
    selected_model_info = None
    
    for model_name, description in optimal_models:
        try:
            model = genai.GenerativeModel(model_name)
            selected_model_info = description
            print(f"âœ… ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸: {model_name} ({description})")
            break
        except Exception as e:
            print(f"âŒ {model_name} ì‚¬ìš© ë¶ˆê°€")
            continue
    
    if model is None:
        print("âš ï¸ ê¸°ë³¸ ëª¨ë¸ë¡œ ì„¤ì •í•©ë‹ˆë‹¤...")
        model = genai.GenerativeModel('gemini-pro')
        selected_model_info = "ê¸°ë³¸ ëª¨ë¸"
        
except Exception as e:
    print(f"ëª¨ë¸ ì„¤ì • ì¤‘ ì˜¤ë¥˜: {e}")
    model = genai.GenerativeModel('gemini-pro')
    selected_model_info = "ê¸°ë³¸ ëª¨ë¸"

@app.get("/", response_class=HTMLResponse)
async def home(request: Request):
    """ë©”ì¸ í˜ì´ì§€"""
    return templates.TemplateResponse("test.html", {"request": request})

@app.get("/test-api")
async def test_api():
    """API í‚¤ í…ŒìŠ¤íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    try:
        print("API í…ŒìŠ¤íŠ¸ ì‹œì‘...")
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ í™•ì¸
        models_info = []
        test_models = ['gemini-1.5-flash', 'gemini-1.5-pro', 'gemini-pro-latest', 'gemini-1.0-pro']
        
        working_model = None
        for model_name in test_models:
            try:
                test_model = genai.GenerativeModel(model_name)
                response = test_model.generate_content("ì•ˆë…•")
                models_info.append({"model": model_name, "status": "ì‘ë™", "response_length": len(response.text)})
                if working_model is None:
                    working_model = model_name
            except Exception as e:
                models_info.append({"model": model_name, "status": "ì˜¤ë¥˜", "error": str(e)[:100]})
        
        return {
            "status": "success" if working_model else "error",
            "working_model": working_model,
            "models_tested": models_info,
            "api_key_valid": working_model is not None
        }
    except Exception as e:
        print(f"API í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
        return {
            "status": "error", 
            "api_key_valid": False,
            "error": str(e)
        }

@app.get("/list-models")
async def list_available_models():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ í™•ì¸"""
    try:
        models = genai.list_models()
        model_list = []
        for m in models:
            if 'generateContent' in m.supported_generation_methods:
                model_list.append({
                    "name": m.name,
                    "display_name": getattr(m, 'display_name', 'N/A'),
                    "supported_methods": m.supported_generation_methods
                })
        return {"available_models": model_list}
    except Exception as e:
        return {"error": str(e)}

@app.post("/ask", response_class=HTMLResponse)
async def ask_gemini(request: Request, question: str = Form(...)):
    """Gemini APIì— ì§ˆë¬¸ì„ ë³´ë‚´ê³  ë‹µë³€ì„ ë°›ëŠ” ì—”ë“œí¬ì¸íŠ¸ - ì¼ë°˜ í…ìŠ¤íŠ¸"""
    try:
        # ì‚¬ìš©ëŸ‰ ì²´í¬ (ê°„ë‹¨í•œ ì œí•œ)
        current_date = time.strftime('%Y-%m-%d')
        current_minute = time.strftime('%Y-%m-%d %H:%M')
        
        # ë‚ ì§œê°€ ë°”ë€Œë©´ ë¦¬ì…‹
        if usage_tracker['last_reset'] != current_date:
            usage_tracker['requests_today'] = 0
            usage_tracker['last_reset'] = current_date
            usage_tracker['requests_this_minute'].clear()
        
        # ë¶„ë‹¹ ìš”ì²­ ìˆ˜ ì²´í¬ (Flash ê¸°ì¤€ 10RPM)
        if usage_tracker['requests_this_minute'][current_minute] >= 8:
            return templates.TemplateResponse("test.html", {
                "request": request,
                "question": question,
                "error": f"ë¶„ë‹¹ ìš”ì²­ í•œë„ ì´ˆê³¼ì…ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”. (í˜„ì¬: {usage_tracker['requests_this_minute'][current_minute]}/8)"
            })
        
        # ì¼ì¼ ìš”ì²­ ìˆ˜ ì²´í¬ (Flash ê¸°ì¤€ 250RPD)
        if usage_tracker['requests_today'] >= 200:
            return templates.TemplateResponse("test.html", {
                "request": request,
                "question": question,
                "error": f"ì¼ì¼ ìš”ì²­ í•œë„ ì´ˆê³¼ì…ë‹ˆë‹¤. ë‚´ì¼ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”. (í˜„ì¬: {usage_tracker['requests_today']}/200)"
            })

        if not question.strip():
            return templates.TemplateResponse("test.html", {
                "request": request,
                "error": "ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."
            })
        
        print(f"ë°›ì€ ì§ˆë¬¸: {question}")
        
        # API í‚¤ ìœ íš¨ì„± í™•ì¸
        if not GEMINI_API_KEY or GEMINI_API_KEY == "YOUR_GEMINI_API_KEY_HERE":
            return templates.TemplateResponse("test.html", {
                "request": request,
                "question": question,
                "error": "API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜ API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."
            })
        
        # ìµœì í™”ëœ ëª¨ë¸ ì‚¬ìš© (ë¬´ë£Œ í• ë‹¹ëŸ‰ ê³ ë ¤)
        try:
            fresh_model = genai.GenerativeModel('gemini-1.5-flash')
        except:
            try:
                fresh_model = genai.GenerativeModel('gemini-1.5-flash-lite')
            except:
                fresh_model = model
        
        print("API í˜¸ì¶œ ì‹œì‘...")
        
        # í”„ë¡¬í”„íŠ¸ ê¸¸ì´ ì²´í¬ ë° ë¶„í•  ì²˜ë¦¬
        prompt_length = len(question)
        print(f"í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {prompt_length}ì")
        
        if prompt_length > 3000:
            print("ê¸´ í”„ë¡¬í”„íŠ¸ ê°ì§€ - ë¶„í•  ì²˜ë¦¬ ì‹œì‘")
            
            # í”„ë¡¬í”„íŠ¸ë¥¼ ë‘ ë¶€ë¶„ìœ¼ë¡œ ë‚˜ëˆ„ê¸°
            mid_point = len(question) // 2
            part1 = question[:mid_point]
            part2 = question[mid_point:]
            
            # ì²« ë²ˆì§¸ ë¶€ë¶„ ì²˜ë¦¬
            response1 = fresh_model.generate_content(
                f"{part1}\n\n[ì´ê²ƒì€ ì²« ë²ˆì§¸ ë¶€ë¶„ì…ë‹ˆë‹¤. ë‘ ë²ˆì§¸ ë¶€ë¶„ì´ ì´ì–´ì§‘ë‹ˆë‹¤.]",
                generation_config=genai.types.GenerationConfig(
                    candidate_count=1,
                    max_output_tokens=2048,
                    temperature=0.7,
                )
            )
            
            # ë‘ ë²ˆì§¸ ë¶€ë¶„ ì²˜ë¦¬ (ì²« ë²ˆì§¸ ì‘ë‹µ í¬í•¨)
            combined_prompt = f"ì´ì „ ì‘ë‹µ: {response1.text}\n\nì´ì–´ì„œ ì²˜ë¦¬í•  ë‚´ìš©: {part2}\n\nìœ„ ë‚´ìš©ì„ ì¢…í•©í•´ì„œ ìµœì¢… ë‹µë³€ì„ í•´ì£¼ì„¸ìš”."
            
            response = fresh_model.generate_content(
                combined_prompt,
                generation_config=genai.types.GenerationConfig(
                    candidate_count=1,
                    max_output_tokens=2048,
                    temperature=0.7,
                )
            )
        else:
            # ì¼ë°˜ ì²˜ë¦¬
            max_tokens = 2048 if prompt_length > 2000 else 1024
            response = fresh_model.generate_content(
                question,
                generation_config=genai.types.GenerationConfig(
                    candidate_count=1,
                    max_output_tokens=max_tokens,
                    temperature=0.7,
                    stop_sequences=None,
                )
            )
        
        print("API í˜¸ì¶œ ì™„ë£Œ")
        
        # ì‚¬ìš©ëŸ‰ ì—…ë°ì´íŠ¸
        usage_tracker['requests_today'] += 1
        usage_tracker['requests_this_minute'][current_minute] += 1
        
        # ì‘ë‹µ í™•ì¸
        if hasattr(response, 'text') and response.text:
            answer = response.text
            print(f"ë‹µë³€ ê¸¸ì´: {len(answer)}")
        else:
            print("ì‘ë‹µì´ ë¹„ì–´ìˆìŒ")
            answer = "ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        return templates.TemplateResponse("test.html", {
            "request": request,
            "question": question,
            "answer": answer,
            "usage_info": f"ì˜¤ëŠ˜ ì‚¬ìš©ëŸ‰: {usage_tracker['requests_today']}/200, ì´ë²ˆ ë¶„: {usage_tracker['requests_this_minute'][current_minute]}/8"
        })
    
    except Exception as e:
        print(f"ìƒì„¸ ì˜¤ë¥˜: {type(e).__name__}: {str(e)}")
        error_message = f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        return templates.TemplateResponse("test.html", {
            "request": request,
            "question": question if 'question' in locals() else "",
            "error": error_message
        })

@app.post("/ask-file", response_class=HTMLResponse)
async def ask_file(request: Request, file: UploadFile = File(...)):
    """íŒŒì¼ ì—…ë¡œë“œë¡œ ì§ˆë¬¸í•˜ê¸° - í•œê¸€ ì¸ì½”ë”© ì§€ì›"""
    try:
        # íŒŒì¼ ê²€ì¦
        if not file.filename.endswith(('.txt', '.md')):
            return templates.TemplateResponse("test.html", {
                "request": request,
                "error": "txt ë˜ëŠ” md íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤."
            })
        
        # íŒŒì¼ ì½ê¸° - ì—¬ëŸ¬ ì¸ì½”ë”© ì‹œë„
        content = await file.read()
        question = None
        
        # í•œêµ­ì–´ íŒŒì¼ì„ ìœ„í•œ ë‹¤ì–‘í•œ ì¸ì½”ë”© ì‹œë„
        encodings_to_try = [
            'utf-8',           # í‘œì¤€ ìœ ë‹ˆì½”ë“œ
            'utf-8-sig',       # BOMì´ ìˆëŠ” UTF-8
            'cp949',           # í•œêµ­ì–´ Windows ê¸°ë³¸
            'euc-kr',          # í•œêµ­ì–´ ë¦¬ëˆ…ìŠ¤/ìœ ë‹‰ìŠ¤
            'ascii',           # ì˜ì–´ë§Œ
            'latin1'           # ë§ˆì§€ë§‰ ìˆ˜ë‹¨
        ]
        
        for encoding in encodings_to_try:
            try:
                question = content.decode(encoding)
                print(f"âœ… íŒŒì¼ì„ {encoding} ì¸ì½”ë”©ìœ¼ë¡œ ì„±ê³µì ìœ¼ë¡œ ì½ì—ˆìŠµë‹ˆë‹¤.")
                print(f"íŒŒì¼ì—ì„œ ì½ì€ ì§ˆë¬¸ ê¸¸ì´: {len(question)}ì")
                break
            except UnicodeDecodeError as e:
                print(f"âŒ {encoding} ì¸ì½”ë”© ì‹¤íŒ¨: {str(e)}")
                continue
        
        if question is None:
            return templates.TemplateResponse("test.html", {
                "request": request,
                "error": "íŒŒì¼ì˜ ì¸ì½”ë”©ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. UTF-8, EUC-KR, CP949 ì¤‘ í•˜ë‚˜ë¡œ ì €ì¥í•´ì£¼ì„¸ìš”."
            })
        
        # ë¹ˆ ë‚´ìš© ì²´í¬
        if not question.strip():
            return templates.TemplateResponse("test.html", {
                "request": request,
                "error": "íŒŒì¼ ë‚´ìš©ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."
            })
        
        # ask_gemini í•¨ìˆ˜ì˜ ë¡œì§ì„ ì¬ì‚¬ìš©
        return await ask_gemini(request, question)
    
    except Exception as e:
        print(f"íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
        return templates.TemplateResponse("test.html", {
            "request": request,
            "error": f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        })

if __name__ == "__main__":
    import uvicorn
    
    # templates ë””ë ‰í† ë¦¬ ìƒì„± (ì—†ëŠ” ê²½ìš°)
    os.makedirs("templates", exist_ok=True)
    
    print("FastAPI ì„œë²„ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    print("ë¸Œë¼ìš°ì €ì—ì„œ http://127.0.0.1:8050 ìœ¼ë¡œ ì ‘ì†í•˜ì„¸ìš”.")
    print("\nğŸ“ API í‚¤ ì„¤ì • ë°©ë²•:")
    print("1. Google AI Studioì—ì„œ API í‚¤ ë°œê¸‰: https://makersuite.google.com/app/apikey")
    print("2. í™˜ê²½ë³€ìˆ˜ ì„¤ì •:")
    print("   Windows: set API_KEY=your_api_key_here")
    print("   Mac/Linux: export API_KEY=your_api_key_here")
    print("3. ë˜ëŠ” .env íŒŒì¼ì— API_KEY=your_api_key_here ì¶”ê°€")
    
    uvicorn.run(app, host="0.0.0.0", port=8050)


# pip install fastapi uvicorn jinja2 python-multipart google-generativeai
# # pip install google-generativeai
# import google.generativeai as genai
# import os
# from dotenv import load_dotenv

# # ----- í™˜ê²½ë³€ìˆ˜ ë¡œë“œ -----
# load_dotenv()
# API_KEY = os.getenv('API_KEY')  # .envì— ì €ì¥ëœ API_KEY ë¶ˆëŸ¬ì˜¤ê¸°

# genai.configure(api_key=API_KEY)

# model = genai.GenerativeModel('gemini-1.5-flash')

# response = model.generate_content("ë„ˆ í•œê¸€ ì˜í•´? ì˜¤ëŠ˜ ë‚ ì”¨ ì•Œë ¤ì¤˜.", stream=True)

text = '''
[ì—­í• ]
ë‹¹ì‹ ì€ í•™ìƒì˜ ì£¼ê°„ ì¶œê²° ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìŠµê´€ ì§„ë‹¨ ë° í–‰ë™ ê°œì„  ì „ëµì„ ì œì•ˆí•˜ëŠ” ì¶œê²° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
[ë¶„ì„ ëª©í‘œ]
1. ì¶œì„ ê³„íšê³¼ ì‹¤ì œ ì¶œê²° ê°„ ì¼ì¹˜ë„ ë¶„ì„ â†’ ë£¨í‹´ ìœ ì§€ë ¥ ì§„ë‹¨
2. ì¶œì„ ì‹œê°„ vs ê³„íš ì‹œê°„ ì°¨ì´ ì •ëŸ‰ ë¶„ì„ â†’ ë£¨í‹´ ì•ˆì •ì„± í‰ê°€
3. ì§€ê°/ì¡°í‡´ ì‚¬ìœ , ìš”ì¼ë³„ ë°˜ë³µì„± ë¶„ì„ â†’ íŒ¨í„´ ì§„ë‹¨ ë° ì›ì¸ íŒŒì•…
4. ì¶œì„ë¥  ë° ì •ìƒ ì¶œì„ì¼ ìˆ˜ ê¸°ë°˜ í‰ê°€ â†’ ë£¨í‹´ ì§€ì† ê°€ëŠ¥ì„± íŒë‹¨
5. ì¦‰ì‹œ ê°œì„ í•  í–‰ë™ ìŠµê´€ or í™˜ê²½ ì¡°ì • ë°©ì•ˆ ì œì‹œ â†’ ì‹¤ì§ˆì  í–‰ë™ ì „ëµ ì œì•ˆ
[ì œì•½ì‚¬í•­]
- ì‹œì‚¬ì ì€ ì „ì²´ êµ¬ì„±ì„ ë¬¸ì¥ 4ì¤„ë¡œë§Œ êµ¬ì„±í•˜ê³ , í•œ ë¬¸ì¥ ë‹¹ ê¸€ì ìˆ˜ëŠ” 85ì ì´ë‚´ë¡œ í•œë‹¤.
- â€œì§€ê°í•˜ì§€ ë§ìâ€, â€œì¶œì„ë¥ ì„ ë†’ì´ìâ€ ê°™ì€ í˜•ì‹ì  ë¬¸ì¥ ê¸ˆì§€
- ë°˜ë“œì‹œ ë°ì´í„° ê¸°ë°˜ ë¶„ì„*í¬í•¨ (ì¶œì„ ì‹œê°„, ì§€ê°/ì¡°í‡´ ì‚¬ìœ , ìš”ì¼ë³„ ë°˜ë³µ ë“±)
- ë¬¸ì œ ì›ì¸ì„ ë£¨í‹´/ì»¨ë””ì…˜/í™˜ê²½(êµí†µ ë“±)ê³¼ ì—°ê²° â†’ í–‰ë™ êµì • or í™˜ê²½ ì¡°ì • ë°©ì‹ìœ¼ë¡œ ì œì•ˆ
- ê²°ì„/ì§€ê°/ì¡°í‡´ ë°œìƒì¼ì€ ë°˜ë“œì‹œ ì›ì¸ ì§„ë‹¨ + ê°œì„  ë°©í–¥ í¬í•¨
[ì¶œë ¥ í˜•ì‹ ì˜ˆì‹œ]
ì¢…í•© ìš”ì•½ ì¸ì‚¬ì´íŠ¸
- ì›”ìš”ì¼ê³¼ ê¸ˆìš”ì¼ì€ ì¶œì„ ì‹œê°„ì´ ê³„íšê³¼ ê±°ì˜ ì¼ì¹˜í•´ ë£¨í‹´ ìœ ì§€ê°€ ì˜ ë˜ê³  ìˆìŒ
- í™”Â·ëª© ëŠ¦ì ìœ¼ë¡œ ì§€ê°ì´ ë°œìƒí•´ ìˆ˜ë©´ ê´€ë¦¬ì™€ ì•ŒëŒ ê°•í™”ê°€ í•„ìš”í•¨.
- ì›”Â·ìˆ˜Â·ê¸ˆ ì™¸ë¶€ ì•½ì†ìœ¼ë¡œ ì¡°í‡´ê°€ ë°˜ë³µë˜ì–´ ì¼ì • ì¡°ì •ê³¼ ë³´ì¶© ê³„íšì´ í•„ìš”í•¨.
- ìˆ˜ìš”ì¼ì— íšŒë³µ ì‹œê°„ì„ ê³ ë ¤í•´ ì „ë‚ (í™”ìš”ì¼) ì¼ì • ì¡°ì • ë˜ëŠ” êµí†µ ëŒ€ì•ˆ í™•ë³´ê°€ í•„ìš”í•¨
- ì¶œì„ë¥ ì€ 75%ë¡œ ìœ ì§€ ì¤‘ì´ë‚˜, ì£¼ì¤‘ ì¤‘ë°˜ ë¦¬ë“¬ì„ ì •ë¹„í•˜ì§€ ì•Šìœ¼ë©´ ì „ì²´ ì£¼ê°„ ë£¨í‹´ ë¶•ê´´ ìš°ë ¤ê°€ ìˆìŒ
- í™”~ìˆ˜ëŠ” í”¼ë¡œë„ ë˜ëŠ” í™˜ê²½ ìš”ì¸(ë²„ìŠ¤ ì§€ì—°, ì»¨ë””ì…˜ ì €í•˜ ë“±)ìœ¼ë¡œ ì¶œê²° íŒ¨í„´ ë¶•ê´´ê°€ ë°˜ë³µë˜ëŠ” êµ¬ì¡°. ì›”ìš”ì¼ê³¼ ê¸ˆìš”ì¼ì€ ì¶œì„ ì‹œê°„ì´ ê³„íšê³¼ ê±°ì˜ ì¼ì¹˜í•´ ë£¨í‹´ ìœ ì§€ê°€ ì˜ ë˜ê³  ìˆìŒ
'''



# for chunk in response:
#     print(chunk.text, end='', flush=True)